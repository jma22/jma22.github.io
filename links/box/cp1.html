<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" href="../links.css">
</head>

<body>
<h1>Checkpoint 1: Square</h1>
    <h2> Data:</h2>
    <p>The data was generated by producing 4 random numbers for the rectangle. (Since a rectangle that is perpendicular
        to the x and y axis only has 4 unique cooridnates). Then there's a 50% change to create a point inside the
        rectangle or outside the rectangle. The coordinates were also limited between 0 and 100.
    </p>
    <p> So the data would consist of [(coordinate of corners of polygon), (target point),(1 if in polygon)]</p>
    <h2>NaiveNet</h2>
    <p> First neural net I designed was the straightforward, 3 layer, fully connected one. So without any data
        processing, I just put the raw coordinates in, and trained this bad boy. I used 20000 data points to train the
        data, and another 2000 to validate. Prior activations were Relus, and the final layer is a sigmoid. I used
        binary cross entropy loss and an adam optimizer.</p>
    <center>
        <img src="../../media/box/naivenetmodel.png" width="30%" height="30%"></img>
        <p>Model</p>
    </center>
    <h2>Results:</h2>
    <center>
        <img src="../../media/box/naivenetloss.png" width="60%" height="60%"></img>
        <p>Loss over iterations</p>
    </center>
    <center>
        <img src="../../media/box/naivenetacc.png" width="60%" height="60%"></img>
        <p> Test/Train accuracy over iterations (Train accuracy is off by a factor of 10)
        </p>
    </center>
    <p>I think one major difficulty in this task is to draw the polygon, since the neural network technically has no
        sense of how this polygon would be drawn, given the points, but since these points are perpendicular to the x
        and y axis, order does not matter that much for now.</p>
    <p>I have to say I did not expect this to work at all.But it did! Surprisingly, the loss does not decrease
        monotonically like the accuracy. But rather fluctuates quite a bit. So now that this task is proven to be
        doable, I'll be making some tweaks to optimize this net.</p>
    <hr>
    <h2>Optimizations: (Or basically methods to regularize)</h2>
    <p>Batch training</p>
    <p> First create a list of indices, randomly shuffle them. Then take batch size number of them and train those down
        the list to ensure no repeated data.</p>
    <center>
        <img src="../../media/box/batchloss.png" width="60%" height="60%"></img>
        <p>Loss over iterations</p>
    </center>
    <center>
        <img src="../../media/box/batchacc.png" width="60%" height="60%"></img>
        <p> Test/Train accuracy over iterations
        </p>
    </center>
    <p> It seems like the loss gets more steady as the batch size increases, however it takes longer to converge.</p>
    <hr>
    <p>Architecture</p>
    <p> Next step is to see if we can change up the architecture to make the process faster.</p>
    <p> I tried 4 networks.</p>
    <figure>
        <img src="../../media/box/simpletonmodel.png" width="150px" height="275px"></img>
        <figcaption>Simpleton</figcaption>
    </figure>
    <figure>
        <img src="../../media/box/layer2model.png" width="150px" height="275px"></img>
        <figcaption>Layer2</figcaption>
    </figure>
    <figure>
        <img src="../../media/box/layer2convmode.png" width="150px" height="275px"></img>
        <figcaption>Layer2conv</figcaption>
    </figure>
    <figure>
        <img src="../../media/box/layer2divmodel.png" width="150px" height="275px"></img>
        <figcaption>Layer2div</figcaption>
    </figure>



    <p>Results:</p>
    <center>
        <img src="../../media/box/layer2loss.png" width="60%" height="60%"></img>
        <p>loss</p>
    </center>
    <center>
        <img src="../../media/box/layer2acc.png" width="60%" height="60%"></img>
        <p>acc</p>
    </center>
    <p> Some interesting observations. Obviously, simpleton did not work, however the normal 2 layer network also did
        not work. HOWEVER, if we put some sort of diverging/converging in the network, it seems like the network was
        able to achieve a significantly better result. This begs the question: Does converging/diverging affect results
        depending on task?</p>
    <hr>
    <p>Dropout layers</p>
    <p> In order to determine to effect of dropout layers, I decided to use the 2 layer net to see how dropout improve/
        worsens the network.</p>
    <p>Results:</p>
    
    <center>
        <img src="../../media/box/dropoutacc.png" width="60%" height="60%"></img>
        <p>acc</p>
    </center>
    <p> Surprisingly, adding dropout seems to only decrease the convergence rate and final result of the network! Which is different from what most websites say how dropout layers always help generalization.</p>
    <hr>
    <p>Extras:</p>
    <p>Luck</p>
    <p> It also seemed like 'luck' is involved due to local minimas. Here are two runs of the layer 2 network.</p>
    <center>
        <img src="../../media/box/luck.png" width="60%" height="60%"></img>
        <p>acc</p>
    </center>
    <p> Scaling the data</p>
    <p> Since coordinates are all the same scale and range, this turns out to not matter as much.</p>
    <p>L2 regularization (Weight decay)</p>
    <p>Early stopping</p>

</body>